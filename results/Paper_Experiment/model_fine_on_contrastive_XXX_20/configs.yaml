# =================================================================
# üìå Project Metadata
# =================================================================
project_title: "model_fine_on_contrastive_XXX_20"
grid_search_vit:
  lr: [0.001,0.001,0.001,0.001,0.001]
  lr_gamma: [0.90]
  step_size: [15]
  weight_decay: [0.0]    #---------- changing
  dropout: [0.2]
  optimizer: ["Adam"]


loss_function: "crossentropy" 
project_description: |

  Fine On Contrastive model
print_acc_per_class: False
files_to_copy:
  - configs.yaml
  - trainer.py
  - Vit.py
  - losses.py
# =================================================================
# üìÅ Dataset and Storage Configuration
# =================================================================
dataset_path_local: "D:/Hossein/datasets/OSC2018"
dataset_path_server: "/home/ha168/datasets/wireless/"

simulating_dataset: 
rml_2018_dataset: "wireless_randomize_snr_0_22_20000.h5"    # "simulated_3000.h5" or "wireless_randomize_snr_0_22_20000.h5"
result_path: "results"
shuffle_before_split: True
data_length: 300000
snr_range: [-2, 21]

# =================================================================
# üß™ Dataset Splitting and Labeling
# =================================================================
labeled_percent: 20   # % of samples that are labeled in training
train_class_indices: [3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22]
current_classes:
  - "BPSK"
  - "QPSK"
  - "8PSK"
  - "16APSK"
  - "32APSK"
  - "64APSK"
  - "128APSK"
  - "16QAM"
  - "32QAM"
  - "64QAM"
  - "128QAM"
  - "256QAM"
  - "AM-DSB-SC"
  - "AM-DSB-WC"
  - "FM"
  - "GMSK"
total_class:
  - "OOK"
  - "4ASK"
  - "8ASK"
  - "BPSK"
  - "QPSK"
  - "8PSK"
  - "16PSK"
  - "32PSK"
  - "16APSK"
  - "32APSK"
  - "64APSK"
  - "128APSK"
  - "16QAM"
  - "32QAM"
  - "64QAM"
  - "128QAM"
  - "256QAM"
  - "AM-SSB-WC"
  - "AM-SSB-SC"
  - "AM-DSB-WC"
  - "AM-DSB-SC"
  - "FM"
  - "GMSK"
  - "OQPSK"


# =================================================================
# ‚öôÔ∏è Model Configuration
# =================================================================
in_channels: 1
in_size: [2, 512]
patch_size: [2, 32]
embed_dim: 64
num_layers: 8
num_heads: 8
mlp_dim: 64 # it was 32
output_dim: 64
classifier_type: "patch_average"  # "patch_average" or "cls_token"
frozen_parts: []

# =================================================================
# üß† Training Configuration
# =================================================================
batch_size: 128
max_epochs: 100

use_gpu: "auto"   # Options: "auto", "cpu", "cuda"
gpu_num: 0
pretrained_path:   "pretrained/model_model_pretrain_contrastive_2_run1.pth" #"pretrained/model_model_pretrain_all_new_config_run1.pth"

# =================================================================
# üéØ Loss Weights and Learning Objectives
# =================================================================
w_classification: 1
w_reconstruction: 0
w_contrastive: 0
contrastive_temperature: 0.09
selftraining_confidence_threshold: 0.8
pseudo_label_weight: 0.5
ema_decay: 0.9999

# =================================================================
# üîÅ Augmentation Configuration
# =================================================================
Aug_prob: 1
Aug_type: "one"  # Options: "one" or "all"
augmentation:
  weak:
    - gaussian_noise
    - scale
    # - rotate
    # - flip_horizontal
    # - flip_vertical
    # - time_warp
    # - magnitude_warp
  full:
    - gaussian_noise
    - scale
    - rotate
    - flip_horizontal
    - flip_vertical
    - time_warp
    - magnitude_warp
